{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcKT1TJVc2Nn",
        "outputId": "fae14ae2-911b-4e33-e770-56e8487c7ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Accuracy: 0.8187283191422264\n",
            "Recall: 0.5434279705573081\n",
            "Precision: 0.2688865764828304\n",
            "F1_score: 0.3597633136094674\n"
          ]
        }
      ],
      "source": [
        "#naive bayes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the training data\n",
        "df = pd.read_csv('/content/heart_disease_health_indicators_BRFSS2015.csv')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "X = df.drop(['HeartDiseaseorAttack'] , axis = 1)\n",
        "\n",
        "y = np.array(df['HeartDiseaseorAttack'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2)\n",
        "\n",
        "\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "  \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "y = label_encoder.fit_transform(y)\n",
        "y_test = label_encoder.fit_transform(y_test)\n",
        "\n",
        "y_pred = label_encoder.fit_transform(y_pred)\n",
        "\n",
        "accuracy1 = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy1)\n",
        "recall1 = recall_score(y_test, y_pred)\n",
        "print('Recall:', recall1)\n",
        "precision1 = precision_score(y_test, y_pred)\n",
        "print('Precision:', precision1)\n",
        "f11 = f1_score(y_test,y_pred)\n",
        "print('F1_score:', f11)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/heart_disease_health_indicators_BRFSS2015.csv')\n",
        "\n",
        "X = df.drop(['HeartDiseaseorAttack'] , axis = 1)\n",
        "y = np.array(df['HeartDiseaseorAttack'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "\n",
        "\n",
        "svm = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
        "\n",
        "\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "accuracy2 = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy2)\n",
        "recall2 = recall_score(y_test, y_pred,pos_label=1)\n",
        "print('Recall:', recall2)\n",
        "precision2 = precision_score(y_test, y_pred,pos_label=1)\n",
        "print('Precision:', precision2)\n",
        "f12 = f1_score(y_test,y_pred,pos_label=1)\n",
        "print('F1_score:', f12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvMbd7ybe1q6",
        "outputId": "072f812c-4332-440e-8a07-e6d0c5580aa7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202944\n",
            "50736\n",
            "Accuracy: 0.9060233364869127\n",
            "Recall: 0.0\n",
            "Precision: 0.0\n",
            "F1_score: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7TJBmll7qQE",
        "outputId": "fe7f6eba-ca2f-41a0-b1c2-fc9a10af174e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#GradientBoostingClassifier\n",
        "\n",
        "# Import models and utility functions\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Setting SEED for reproducibility\n",
        "SEED = 23\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/heart_disease_health_indicators_BRFSS2015.csv')\n",
        "df\n",
        "x=df.drop(['HeartDiseaseorAttack'],axis=1)\n",
        "x\n",
        "y=np.array(df['HeartDiseaseorAttack'])\n",
        "# Importing the dataset\n",
        "\n",
        " \n",
        "# Splitting dataset\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y,\n",
        "                                                    test_size = 0.25,\n",
        "                                                    random_state = SEED)\n",
        " \n",
        "# Instantiate Gradient Boosting Regressor\n",
        "gbc = GradientBoostingClassifier(n_estimators=300,\n",
        "                                 learning_rate=0.05,\n",
        "                                 random_state=100,\n",
        "                                 max_features=5 )\n",
        "# Fit to training set\n",
        "gbc.fit(train_x, train_y)\n",
        " \n",
        "# Predict on test set\n",
        "pred_y = gbc.predict(test_x)\n",
        " \n",
        "from sklearn import preprocessing\n",
        "  \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "y = label_encoder.fit_transform(y)\n",
        "test_y = label_encoder.fit_transform(test_y)\n",
        "pred_y = label_encoder.fit_transform(pred_y)\n",
        "\n",
        "\n",
        "\n",
        "accuracy3 = accuracy_score(test_y, pred_y)\n",
        "print('Accuracy:', accuracy3)\n",
        "recall3 = recall_score(test_y, pred_y)\n",
        "print('Recall:', recall3)\n",
        "precision3 = precision_score(test_y, pred_y)\n",
        "print('Precision:', precision3)\n",
        "f13 = f1_score(test_y,pred_y)\n",
        "print('F1_score:', f13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRypkRPshxt4",
        "outputId": "a1aae7dc-4983-4d6b-b001-e3926f3c3c7e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9077262693156732\n",
            "Recall: 0.11639591358231452\n",
            "Precision: 0.5468135326514555\n",
            "F1_score: 0.191935929301298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load sample data\n",
        "df = pd.read_csv('/content/heart_disease_health_indicators_BRFSS2015.csv')\n",
        "df\n",
        "x=df.drop(['HeartDiseaseorAttack'],axis=1)\n",
        "x\n",
        "y=np.array(df['HeartDiseaseorAttack'])\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "# Create an MLP classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, ),        # Number of hidden layers and units per layer\n",
        "                    activation='relu',                 # Activation function ('identity', 'logistic', 'tanh', 'relu')\n",
        "                    solver='adam',                     # Solver for weight optimization ('lbfgs', 'sgd', 'adam')\n",
        "                    alpha=0.0001,                      # L2 penalty (regularization term) parameter\n",
        "                    batch_size='auto',                 # Size of minibatches for stochastic optimizers\n",
        "                    learning_rate='adaptive',          # Learning rate schedule ('constant', 'invscaling', 'adaptive')\n",
        "                    learning_rate_init=0.005,          # The initial learning rate\n",
        "                    power_t=0.5,                       # The exponent for inverse scaling learning rate\n",
        "                    max_iter=200,                      # Maximum number of iterations\n",
        "                    shuffle=True,                      # Whether to shuffle samples in each iteration\n",
        "                    random_state=None,                 # Seed for the random number generator\n",
        "                    tol=0.0001,                        # Tolerance for the optimization\n",
        "                    verbose=False,                     # Whether to print progress messages\n",
        "                    warm_start=False,                  # Reuse the previous solution\n",
        "                    momentum=0.9,                      # Momentum for gradient descent update\n",
        "                    nesterovs_momentum=True,           # Whether to use Nesterov's momentum\n",
        "                    early_stopping=False,              # Terminate training when validation score is not improving\n",
        "                    validation_fraction=0.1,           # Proportion of training data to set aside as validation set\n",
        "                    beta_1=0.9,                        # Exponential decay rate for estimates of first moment vector in adam\n",
        "                    beta_2=0.999,                      # Exponential decay rate for estimates of second moment vector in adam\n",
        "                    epsilon=1e-8,                      # Value for numerical stability in adam\n",
        "                    n_iter_no_change=10,               # Maximum number of epochs without any improvement in the loss\n",
        "                    max_fun=15000)                     # Maximum number of function calls for the solver\n",
        "\n",
        "# Train the MLP classifier\n",
        "mlp.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = mlp.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "  \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "y = label_encoder.fit_transform(y)\n",
        "test_y = label_encoder.fit_transform(y_test)\n",
        "pred_y = label_encoder.fit_transform(y_pred)\n",
        "\n",
        "\n",
        "\n",
        "accuracy4 = accuracy_score(test_y, pred_y)\n",
        "print('Accuracy:', accuracy4)\n",
        "recall4 = recall_score(test_y, pred_y)\n",
        "print('Recall:', recall4)\n",
        "precision4= precision_score(test_y, pred_y)\n",
        "print('Precision:', precision4)\n",
        "f14 = f1_score(test_y,pred_y)\n",
        "print('F1_score:', f14)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iZ1EoWnxiwmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92282eb-97d9-4968-8ac5-51f455aec83d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9072650583412173\n",
            "Recall: 0.11558522845816817\n",
            "Precision: 0.5431372549019607\n",
            "F1_score: 0.19060725959057284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = pd.read_csv('/content/heart_disease_health_indicators_BRFSS2015.csv')\n",
        "\n",
        "X = data.drop(['HeartDiseaseorAttack'] , axis = 1)\n",
        "y = np.array(data['HeartDiseaseorAttack'])\n",
        "\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classifier = LogisticRegression(solver='lbfgs',random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "predicted_y = classifier.predict(X_test)\n",
        "from sklearn import preprocessing\n",
        "  \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "y = label_encoder.fit_transform(y)\n",
        "test_y = label_encoder.fit_transform(y_test)\n",
        "pred_y = label_encoder.fit_transform(predicted_y)\n",
        "\n",
        "\n",
        "\n",
        "accuracy5 = accuracy_score(test_y, pred_y)\n",
        "print('Accuracy:', accuracy5)\n",
        "recall5 = recall_score(test_y, pred_y)\n",
        "print('Recall:', recall5)\n",
        "precision5= precision_score(test_y, pred_y)\n",
        "print('Precision:', precision5)\n",
        "f15 = f1_score(test_y,pred_y)\n",
        "print('F1_score:', f15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb0RWO2YlWq4",
        "outputId": "408d8ec0-9c7e-47f7-e214-7fccc2ea6541"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9065752128666036\n",
            "Recall: 0.1294043624161074\n",
            "Precision: 0.511608623548922\n",
            "F1_score: 0.2065617676598594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#knn\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "# Load the training data\n",
        "df = pd.read_csv('/content/heart_disease_health_indicators_BRFSS2015.csv')\n",
        "\n",
        "# Create feature and target arrays\n",
        "X = X = df.drop(['HeartDiseaseorAttack'] , axis = 1)\n",
        "\n",
        "y = np.array(df['HeartDiseaseorAttack'])\n",
        "\n",
        "\n",
        "\n",
        "# Split into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "             X, y, test_size = 0.2, random_state=42)\n",
        "  \n",
        "neighbors = np.arange(1, 9)\n",
        "train_accuracy = np.empty(len(neighbors))\n",
        "test_accuracy = np.empty(len(neighbors))\n",
        "  \n",
        "\n",
        "\n",
        "# Loop over K values\n",
        "\n",
        "#for i, k in enumerate(neighbors):\n",
        "#    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "#    knn.fit(X_train, y_train)\n",
        "      \n",
        "#    # Compute training and test data accuracy\n",
        " #   train_accuracy[i] = knn.score(X_train, y_train)\n",
        "  #  test_accuracy[i] = knn.score(X_test, y_test)\n",
        "\n",
        "  \n",
        "\n",
        "knn = KNeighborsClassifier(49)\n",
        "knn.fit(X_train, y_train)\n",
        "# Predict on test set\n",
        "pred_y = knn.predict(X_test)\n",
        " \n",
        "from sklearn import preprocessing\n",
        "  \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "y = label_encoder.fit_transform(y)\n",
        "test_y = label_encoder.fit_transform(y_test)\n",
        "pred_y = label_encoder.fit_transform(pred_y)\n",
        "\n",
        "\n",
        "\n",
        "accuracy6 = accuracy_score(test_y, pred_y)\n",
        "print('Accuracy:', accuracy6)\n",
        "recall6 = recall_score(test_y, pred_y)\n",
        "print('Recall:', recall6)\n",
        "precision6 = precision_score(test_y, pred_y)\n",
        "print('Precision:', precision6)\n",
        "f16 = f1_score(test_y,pred_y)\n",
        "print('F1_score:', f16)\n"
      ],
      "metadata": {
        "id": "TKb9rT6xoGr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1221652d-8b92-4163-9692-5457ea930e98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9064766635130873\n",
            "Recall: 0.009228187919463088\n",
            "Precision: 0.676923076923077\n",
            "F1_score: 0.018208152286364576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Accuracy: 0.8971341847997477\n",
        "Recall: 0.10864093959731544\n",
        "Precision: 0.34835238735709484\n",
        "F1_score: 0.1656274980015987"
      ],
      "metadata": {
        "id": "UzSKRryW58IN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "table = [[\"Classsifier name\", \"Accuracy\", \"Recall\", \"Precision\",\"f1-score\"], \n",
        "         [\"Naive bayes\", accuracy1, recall1, precision1,f11], \n",
        "         [\"SVM\", accuracy2, recall2, precision2,f12], \n",
        "         [\"Gradient Boosting\", accuracy3, recall3, precision3,f13],\n",
        "         [\"MLP\", accuracy4, recall4, precision4,f14],\n",
        "         [\"Logistic regression\", accuracy5, recall5, precision5,f15],\n",
        "         [\"KNN\", accuracy6, recall6, precision2,f16]\n",
        "         ]\n",
        "\n",
        "\n",
        "\n",
        "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTKiKve_a-h4",
        "outputId": "59f8be14-6ae2-4b30-8f3f-df418d9a1c4f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒═════════════════════╤════════════╤════════════╤═════════════╤════════════╕\n",
            "│ Classsifier name    │   Accuracy │     Recall │   Precision │   f1-score │\n",
            "╞═════════════════════╪════════════╪════════════╪═════════════╪════════════╡\n",
            "│ Naive bayes         │   0.818728 │ 0.543428   │    0.268887 │  0.359763  │\n",
            "├─────────────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ SVM                 │   0.906023 │ 0          │    0        │  0         │\n",
            "├─────────────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Gradient Boosting   │   0.907726 │ 0.116396   │    0.546814 │  0.191936  │\n",
            "├─────────────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ MLP                 │   0.907265 │ 0.115585   │    0.543137 │  0.190607  │\n",
            "├─────────────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Logistic regression │   0.906575 │ 0.129404   │    0.511609 │  0.206562  │\n",
            "├─────────────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ KNN                 │   0.906477 │ 0.00922819 │    0        │  0.0182082 │\n",
            "╘═════════════════════╧════════════╧════════════╧═════════════╧════════════╛\n"
          ]
        }
      ]
    }
  ]
}